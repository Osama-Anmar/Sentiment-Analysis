{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from tensorflow import *\n",
    "from keras.preprocessing import *\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from utils.textnormalization import TextNormalization\n",
    "from utils.machinelearning import machine_learning_model, fit_model\n",
    "from utils.deeplearning import model_compile, model_fit, lstm_, gru_, bidirectional_lstm\n",
    "from utils.plot_model_changes import plot_changes\n",
    "from utils.sentimentinformation import sentiment_percentage, sentiment_counts\n",
    "from utils.wordcloud import wordcloud\n",
    "from utils.most_frequent_word_plot import bar_plot\n",
    "from utils.deeplearning_preprcosesing import  deeplearning_preprcosesing_\n",
    "from utils.word_vector import word_vector_\n",
    "from utils.word_2_vec import word_2_vec_\n",
    "from utils.confusion_matrix import confusion_matrix_, confusion_matrix_display\n",
    "from utils.generate_poitive_negative import false_true_positive, false_true_negative\n",
    "from utils.performance_metrics import accuracy_score, precision_score, sensitivity_score, specificity_score, f1_score, error_rate, performance_metrics_data_frame\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns =None \n",
    "tf.keras.utils.set_random_seed(1)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Some Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = pd.read_csv('IMDB Dataset.csv')\n",
    "Corpus.rename(columns={'review': 'Review', 'sentiment': 'Sentiment'}, inplace=True)\n",
    "Corpus['Sentiment'] = Corpus['Sentiment'].str.capitalize()\n",
    "Corpus.index = Corpus.index + 1\n",
    "Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('EnglishData.csv') # This Data Will Be Use For Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_percentage(Corpus, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts(Corpus, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus['NumberOfSentences'] = Corpus['Review'].apply(lambda n:len(sent_tokenize(n)))\n",
    "Corpus.drop(Corpus[Corpus[\"NumberOfSentences\"] == 0].index, inplace = True)\n",
    "Corpus['NumberOfSentences'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfSentence = int(np.round(Corpus[\"NumberOfSentences\"].mean()))\n",
    "AverageNumberOfSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfSentence = Corpus[\"NumberOfSentences\"].max()\n",
    "MaximumNumberOfSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfSentence = Corpus[\"NumberOfSentences\"].min()\n",
    "MinimumNumberOfSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Words Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"Number of Words 1\"] = Corpus[\"Review\"].apply(lambda n:len(tokenizer.tokenize(n)))\n",
    "Corpus[\"Number of Words 1\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Words Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNaumberOfWords1 = int(np.round((Corpus[\"Number of Words 1\"].mean())))\n",
    "AverageNaumberOfWords1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Word Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNaumberOfWords1 = Corpus[\"Number of Words 1\"].max()\n",
    "MaximumNaumberOfWords1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Words Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MimimumNaumberOfWords1 = Corpus[\"Number of Words 1\"].min()\n",
    "MimimumNaumberOfWords1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Charachters Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"Number of Charachters 1\"] = Corpus[\"Review\"].apply(lambda n:sum(chr.isalpha() for chr in n))\n",
    "Corpus[\"Number of Charachters 1\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Charachters Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfCharachters1 = int(np.round(Corpus[\"Number of Charachters 1\"].mean()))\n",
    "AverageNumberOfCharachters1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Charachters Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfCharachters1 = Corpus['Number of Charachters 1'].max() \n",
    "MaximumNumberOfCharachters1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Charachters Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfCharachters1 = Corpus['Number of Charachters 1'].min() \n",
    "MinimumNumberOfCharachters1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent Words Before Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MostFrequentWord1 = Counter((Corpus['Review']).str.split().explode()).most_common(15)\n",
    "MostFrequentWordDF1 = pd.DataFrame(MostFrequentWord1, columns=('Word', 'Count'), index=range(1, 16))\n",
    "MostFrequentWordDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(data=MostFrequentWordDF1,  x = 'Word', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalization =TextNormalization(string_lower= True,\n",
    "                 remove_emojis= True,\n",
    "                 remove_hashtags= True,\n",
    "                 remove_emails= True,\n",
    "                 remove_URLs= True,\n",
    "                 remove_mentions= True,\n",
    "                 remove_html_tags= True,\n",
    "                 remove_new_line_char= True,\n",
    "                 decrease_number_of_consecutive_reapted_letter= True,\n",
    "                 remove_duplicate_word= True,\n",
    "                 remove_single_letter= True,\n",
    "                 remove_duplicated_letter= True,\n",
    "                 expand_contractions= True,\n",
    "                 remove_stop_words= True,\n",
    "                 remove_unicode_and_special_character= True,\n",
    "                 remove_puncuations= True,\n",
    "                 remove_numbers= True,\n",
    "                 english_spell_coreccter= True,\n",
    "                 remove_non_english= True,\n",
    "                 remove_longest_than= True,\n",
    "                 remove_whitespace= True,\n",
    "                 lemmatize= False,\n",
    "                 stemmer= False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus['Normalized_Review'] = Corpus['Review'].apply(text_normalization.normalization)\n",
    "Corpus.dropna(axis=1, inplace=True)\n",
    "Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.to_csv('Normalized Corpus.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueWords = set()\n",
    "for word in Corpus['Normalized_Review'].str.split():\n",
    "    UniqueWords.update(word)\n",
    "\n",
    "len(UniqueWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Corpus, target='Positive', width=1600, hieght=800, review='Normalized_Review', max_words= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Corpus, target='Negative', width=1600, hieght=800, review='Normalized_Review', max_words= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Words After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"Number of Words 2\"] = Corpus[\"Normalized_Review\"].apply(lambda n:len(tokenizer.tokenize(n)))\n",
    "Corpus.drop(Corpus[Corpus[\"Number of Words 2\"] == 0].index, inplace = True)\n",
    "Corpus[\"Number of Words 2\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Words After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNaumberOfWords2 = int(np.round((Corpus[\"Number of Words 2\"].mean())))\n",
    "AverageNaumberOfWords2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Word After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNaumberOfWords2 = Corpus[\"Number of Words 2\"].max()\n",
    "MaximumNaumberOfWords2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Words After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MimimumNaumberOfWords2 = Corpus[\"Number of Words 2\"].min()\n",
    "MimimumNaumberOfWords2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Charachters After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"Number of Charachters 2\"] = Corpus[\"Normalized_Review\"].apply(lambda n:sum(chr.isalpha() for chr in n))\n",
    "Corpus[\"Number of Charachters 2\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Charachters After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfCharachters2 = int(np.round(Corpus[\"Number of Charachters 2\"].mean()))\n",
    "AverageNumberOfCharachters2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Charachters After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfCharachters2 = Corpus['Number of Charachters 2'].max() \n",
    "MaximumNumberOfCharachters2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Charachters After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfCharachters2 = Corpus['Number of Charachters 2'].min() \n",
    "MinimumNumberOfCharachters2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent Words After Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MostFrequentWord2 = Counter((Corpus['Normalized_Review']).str.split().explode()).most_common(15)\n",
    "MostFrequentWordDF2 = pd.DataFrame(MostFrequentWord2, columns=('Word', 'Count'), index=range(1, 16))\n",
    "MostFrequentWordDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(data=MostFrequentWordDF2, x = 'Word', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent Words Of Each Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Positive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = Corpus[Corpus['Sentiment'] == 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PositiveMostFrequentWord = Counter((Positive['Normalized_Review']).str.split().explode()).most_common(10)\n",
    "PositiveMostFrequentWordDF = pd.DataFrame(PositiveMostFrequentWord, columns=('Word', 'Count'), index=range(1, 11))\n",
    "PositiveMostFrequentWordDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Negative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative = Corpus[Corpus['Sentiment'] == 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NegativeMostFrequentWord = Counter((Negative['Normalized_Review']).str.split().explode()).most_common(10)\n",
    "NegativeMostFrequentWordDF = pd.DataFrame(NegativeMostFrequentWord, columns=('Word', 'Count'), index=range(1, 11))\n",
    "NegativeMostFrequentWordDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset Into Dependent (X) And Independent (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Corpus['Normalized_Review'], Corpus['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Dependent Variables (Y) Into Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset Into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0,  stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = TfidfVectorizer()\n",
    "X_train_Vec = Vectorizer.fit_transform(X_train)\n",
    "X_test_Vec = Vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_mapping = Vectorizer.vocabulary_\n",
    "Word_mapping_ =pd.DataFrame(sorted((list(Word_mapping.items()))), columns=['Word', 'Mapping'])\n",
    "Word_mapping_['Word'].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = MultinomialNB(alpha= 1)\n",
    "Naive_Bayes = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Naive_Bayes, X_train=X_train_Vec, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predNB = Naive_Bayes.predict(X_test_Vec)\n",
    "ConfusionMatrixNB = confusion_matrix_(y_test = y_test, y_pred = y_predNB)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixNB, name = 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveNB, True_PositiveNB = false_true_positive(Confusin_Matrix = ConfusionMatrixNB)\n",
    "False_NegativeNB, True_NegativeNB = false_true_negative(Confusin_Matrix = ConfusionMatrixNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyNB = accuracy_score(True_Positive = True_PositiveNB, True_Negative = True_NegativeNB, False_Positive =False_PositiveNB, False_Negative = False_NegativeNB)\n",
    "PrecisionNB= precision_score(True_Positive = True_PositiveNB, False_Positive= False_PositiveNB)\n",
    "\n",
    "SensitivityNB = sensitivity_score(True_Positive = True_PositiveNB,  False_Negative = False_NegativeNB)\n",
    "SpecificityNB = specificity_score(True_Negative = True_NegativeNB, False_Positive = False_PositiveNB)\n",
    "\n",
    "F1ScoreNB = f1_score(True_Positive = True_PositiveNB, False_Negative = False_NegativeNB, False_Positive = False_PositiveNB)\n",
    "ErrorNB = error_rate(True_Positive = True_PositiveNB, True_Negative = True_NegativeNB, False_Positive =False_PositiveNB, False_Negative = False_NegativeNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracyNB, Precision = PrecisionNB, Sensitivity = SensitivityNB, Specificity = SpecificityNB, F1Score = F1ScoreNB, Error = ErrorNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = LogisticRegression()\n",
    "Logistic_Regression = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Logistic_Regression, X_train=X_train_Vec, y_train=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predLR = Logistic_Regression.predict(X_test_Vec)\n",
    "ConfusionMatrixLR = confusion_matrix_(y_test = y_test, y_pred = y_predLR)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixLR, name = 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveLR, True_PositiveLR = false_true_positive(Confusin_Matrix = ConfusionMatrixLR)\n",
    "False_NegativeLR, True_NegativeLR = false_true_negative(Confusin_Matrix = ConfusionMatrixLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyLR = accuracy_score(True_Positive = True_PositiveLR, True_Negative = True_NegativeLR, False_Positive =False_PositiveLR, False_Negative = False_NegativeLR)\n",
    "PrecisionLR= precision_score(True_Positive = True_PositiveLR, False_Positive= False_PositiveLR)\n",
    "\n",
    "SensitivityLR = sensitivity_score(True_Positive = True_PositiveLR,  False_Negative = False_NegativeLR)\n",
    "SpecificityLR = specificity_score(True_Negative = True_NegativeLR, False_Positive = False_PositiveLR)\n",
    "\n",
    "F1ScoreLR = f1_score(True_Positive = True_PositiveLR, False_Negative = False_NegativeLR, False_Positive = False_PositiveLR)\n",
    "ErrorLR = error_rate(True_Positive = True_PositiveLR, True_Negative = True_NegativeLR, False_Positive =False_PositiveLR, False_Negative = False_NegativeLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracyLR, Precision = PrecisionLR, Sensitivity = SensitivityLR, Specificity = SpecificityLR, F1Score = F1ScoreLR, Error = ErrorLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = DecisionTreeClassifier(criterion='gini', )\n",
    "Decision_Tree = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Decision_Tree, X_train=X_train_Vec, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predDT = Decision_Tree.predict(X_test_Vec)\n",
    "ConfusionMatrixDT = confusion_matrix_(y_test = y_test, y_pred = y_predDT)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixDT, name = 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveDT, True_PositiveDT = false_true_positive(Confusin_Matrix = ConfusionMatrixDT)\n",
    "False_NegativeDT, True_NegativeDT = false_true_negative(Confusin_Matrix = ConfusionMatrixDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyDT = accuracy_score(True_Positive = True_PositiveDT, True_Negative = True_NegativeDT, False_Positive =False_PositiveDT, False_Negative = False_NegativeDT)\n",
    "PrecisionDT= precision_score(True_Positive = True_PositiveDT, False_Positive =False_PositiveDT)\n",
    "\n",
    "SensitivityDT = sensitivity_score(True_Positive = True_PositiveDT,  False_Negative = False_NegativeDT)\n",
    "SpecificityDT = specificity_score(True_Negative = True_NegativeDT, False_Positive = False_PositiveDT)\n",
    "\n",
    "F1ScoreDT = f1_score(True_Positive = True_PositiveDT, False_Negative = False_NegativeDT, False_Positive = False_PositiveDT)\n",
    "ErrorDT = error_rate(True_Positive = True_PositiveDT, True_Negative = True_NegativeDT, False_Positive =False_PositiveDT, False_Negative = False_NegativeDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracyDT, Precision = PrecisionDT, Sensitivity = SensitivityDT, Specificity = SpecificityDT, F1Score = F1ScoreDT, Error = ErrorDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4-K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm =KNeighborsClassifier(metric='minkowski', n_neighbors=5, weights='distance', p=2)\n",
    "K_Nearest_Neighbors = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=K_Nearest_Neighbors, X_train=X_train_Vec, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predKNN = K_Nearest_Neighbors.predict(X_test_Vec)\n",
    "ConfusionMatrixKNN = confusion_matrix_(y_test = y_test, y_pred = y_predKNN)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixKNN, name = 'K Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveKNN, True_PositiveKNN = false_true_positive(Confusin_Matrix = ConfusionMatrixKNN)\n",
    "False_NegativeKNN, True_NegativeKNN = false_true_negative(Confusin_Matrix = ConfusionMatrixKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyKNN = accuracy_score(True_Positive = True_PositiveKNN, True_Negative = True_NegativeKNN, False_Positive =False_PositiveKNN, False_Negative = False_NegativeKNN)\n",
    "PrecisionKNN= precision_score(True_Positive = True_PositiveKNN, False_Positive =False_PositiveKNN)\n",
    "\n",
    "SensitivityKNN = sensitivity_score(True_Positive = True_PositiveKNN,  False_Negative = False_NegativeKNN)\n",
    "SpecificityKNN = specificity_score(True_Negative = True_NegativeKNN, False_Positive = False_PositiveKNN)\n",
    "\n",
    "F1ScoreKNN = f1_score(True_Positive = True_PositiveKNN, False_Negative = False_NegativeKNN, False_Positive = False_PositiveKNN)\n",
    "ErrorKNN = error_rate(True_Positive = True_PositiveKNN, True_Negative = True_NegativeKNN, False_Positive =False_PositiveKNN, False_Negative = False_NegativeKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracyKNN, Precision = PrecisionKNN, Sensitivity = SensitivityKNN, Specificity = SpecificityKNN, F1Score = F1ScoreKNN, Error = ErrorKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = RandomForestClassifier(criterion = 'entropy', n_estimators=100, )\n",
    "Random_Forest = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Random_Forest, X_train=X_train_Vec, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRF = Random_Forest.predict(X_test_Vec)\n",
    "ConfusionMatrixRF = confusion_matrix_(y_test = y_test, y_pred = y_predRF)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixRF, name = 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveRF, True_PositiveRF = false_true_positive(Confusin_Matrix = ConfusionMatrixRF)\n",
    "False_NegativeRF, True_NegativeRF = false_true_negative(Confusin_Matrix = ConfusionMatrixRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyRF = accuracy_score(True_Positive = True_PositiveRF, True_Negative = True_NegativeRF, False_Positive =False_PositiveRF, False_Negative = False_NegativeRF)\n",
    "PrecisionRF= precision_score(True_Positive = True_PositiveRF, False_Positive =False_PositiveRF)\n",
    "\n",
    "SensitivityRF = sensitivity_score(True_Positive = True_PositiveRF,  False_Negative = False_NegativeRF)\n",
    "SpecificityRF = specificity_score(True_Negative = True_NegativeRF, False_Positive = False_PositiveRF)\n",
    "\n",
    "F1ScoreRF = f1_score(True_Positive = True_PositiveRF, False_Negative = False_NegativeRF, False_Positive = False_PositiveRF)\n",
    "ErrorRF = error_rate(True_Positive = True_PositiveRF, True_Negative = True_NegativeRF, False_Positive =False_PositiveRF, False_Negative = False_NegativeRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracyRF, Precision = PrecisionRF, Sensitivity = SensitivityRF, Specificity = SpecificityRF, F1Score = F1ScoreRF, Error = ErrorRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6-SGD Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = SGDClassifier(loss='hinge', )\n",
    "SGD = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=SGD, X_train=X_train_Vec, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predSGD = SGD.predict(X_test_Vec)\n",
    "ConfusionMatrixSGD = confusion_matrix_(y_test = y_test, y_pred = y_predSGD)\n",
    "confusion_matrix_display(confusionmatrix = ConfusionMatrixSGD, name = 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_PositiveSGD, True_PositiveSGD = false_true_positive(Confusin_Matrix = ConfusionMatrixSGD)\n",
    "False_NegativeSGD, True_NegativeSGD = false_true_negative(Confusin_Matrix = ConfusionMatrixSGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracySGD = accuracy_score(True_Positive = True_PositiveSGD, True_Negative = True_NegativeSGD, False_Positive =False_PositiveSGD, False_Negative = False_NegativeSGD)\n",
    "PrecisionSGD= precision_score(True_Positive = True_PositiveSGD, False_Positive =False_PositiveSGD)\n",
    "\n",
    "SensitivitySGD = sensitivity_score(True_Positive = True_PositiveSGD,  False_Negative = False_NegativeSGD)\n",
    "SpecificitySGD = specificity_score(True_Negative = True_NegativeSGD, False_Positive = False_PositiveSGD)\n",
    "\n",
    "F1ScoreSGD = f1_score(True_Positive = True_PositiveSGD, False_Negative = False_NegativeSGD, False_Positive = False_PositiveSGD)\n",
    "ErrorSGD = error_rate(True_Positive = True_PositiveSGD, True_Negative = True_NegativeSGD, False_Positive =False_PositiveSGD, False_Negative = False_NegativeSGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_data_frame(Accuracy = AccuracySGD, Precision = PrecisionSGD, Sensitivity = SensitivitySGD, Specificity = SpecificitySGD, F1Score = F1ScoreSGD, Error = ErrorSGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_2_vec_(data = Data['text'], vector_size=100, sg=1, name = 'EnglishWord2Vec100D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, vocab_size, max_length, encoded_X_train , encoded_X_test, word_index = deeplearning_preprcosesing_(X_train=X_train, X_test=X_test, truncating='pre', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Vocab Size Is :',vocab_size)\n",
    "print('')\n",
    "print('The Max Length Is :', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Word Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Index = word_index\n",
    "Word_Index_ =pd.DataFrame(((list(Word_Index.items()))), columns=['Word', 'Index'])\n",
    "Word_Index_.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Generate Word Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'EnglishWord2Vec100D.txt'\n",
    "embedding_dim, word_vector = word_vector_(model_path, vocab_size, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7-LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM =lstm_(vocab_size= vocab_size + 1, embedding_dim= embedding_dim,  units1=64, dropout1=0.5, units2=32, dropout2=0.5, units3=32, dropout3=0.5, embeddings_matrix=word_vector)\n",
    "model_compile(model=LSTM)\n",
    "history = model_fit(model=LSTM, X_train=encoded_X_train, y_train=y_train, epochs=10, X_test=encoded_X_test, y_test=y_test, batch_size=32, name= 'LSTM')\n",
    "plot_changes(histoty=history)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8-GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_=gru_(vocab_size= vocab_size + 1, embedding_dim= embedding_dim,  units1=128, dropout1=0.3, units2=64, dropout2=0.3, units3=32, dropout3=0.3, embeddings_matrix=word_vector)\n",
    "model_compile(model=GRU_)\n",
    "history = model_fit(model=GRU_, X_train=encoded_X_train, y_train=y_train, epochs=10, X_test=encoded_X_test, y_test=y_test, batch_size=32, name='GRU')\n",
    "plot_changes(histoty=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9-Bidirectional LSTM** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bidirectional_LSTM=bidirectional_lstm(vocab_size= vocab_size + 1, embedding_dim= embedding_dim, units1=32, dropout1=0.2, embeddings_matrix=word_vector)\n",
    "model_compile(model=Bidirectional_LSTM)\n",
    "history = model_fit(model=Bidirectional_LSTM, X_train=encoded_X_train, y_train=y_train, epochs=10, X_test=encoded_X_test, y_test=y_test, batch_size=32, name='bio_lstm')\n",
    "plot_changes(histoty=history) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
