{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from tensorflow import *\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import csv\n",
    "import random\n",
    "from collections import Counter\n",
    "from utils.textnormalization import TextNormalization\n",
    "from utils.machinelearning import machine_learning_model, fit_model, metrics_values, confusion_matrix_\n",
    "from utils.deeplearning import convolutional_neural_network_1d, model_compile, model_fit, evaluate, plot_accuracy_loss, lstm_, gru_\n",
    "from utils.sentimentinformation import sentiment_percentage, sentiment_counts\n",
    "from utils.wordcloud import wordcloud\n",
    "from utils.most_frequent_word_plot import go_figure , bar_plot\n",
    "from utils.deeplearning_preprcosesing import  deeplearning_preprcosesing_\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns =None \n",
    "random.seed(40)\n",
    "tf.random.set_seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Some Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('train.csv')\n",
    "Train.rename(columns={'text': 'Review', 'sentiment': 'Sentiment'}, inplace=True)\n",
    "Train['Sentiment'] = Train['Sentiment'].map({'neg': 'Negative', 'pos': 'Positive'})\n",
    "Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv('test.csv')\n",
    "Test.rename(columns={'text': 'Review', 'sentiment': 'Sentiment'}, inplace=True)\n",
    "Test['Sentiment'] = Test['Sentiment'].map({'neg': 'Negative', 'pos': 'Positive'})\n",
    "Test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_percentage(Train, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts(Train, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_percentage(Test, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts(Test, 'Sentiment', (6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['NumberOfSentences'] = Train['Review'].apply(lambda n:len(sent_tokenize(n)))\n",
    "Train.drop(Train[Train[\"NumberOfSentences\"] == 0].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['NumberOfSentences'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test['NumberOfSentences'] = Test['Review'].apply(lambda n:len(sent_tokenize(n)))\n",
    "Test.drop(Test[Test[\"NumberOfSentences\"] == 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test['NumberOfSentences'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfSentence_Train = int(np.round(Train[\"NumberOfSentences\"].mean()))\n",
    "AverageNumberOfSentence_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfSentence_Test = int(np.round(Test[\"NumberOfSentences\"].mean()))\n",
    "AverageNumberOfSentence_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfSentence_Train = Train[\"NumberOfSentences\"].max()\n",
    "MaximumNumberOfSentence_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfSentence_Test = Test[\"NumberOfSentences\"].max()\n",
    "MaximumNumberOfSentence_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfSentence_Train = Train[\"NumberOfSentences\"].min()\n",
    "MinimumNumberOfSentence_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfSentence_Test = Test[\"NumberOfSentences\"].min()\n",
    "MinimumNumberOfSentence_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalization = TextNormalization(_string_lower = True, \n",
    "                        _remove_emojis = True, \n",
    "                        _remove_hashtags = True, \n",
    "                        _remove_emails = True,\n",
    "                        _remove_url = True, \n",
    "                        _remove_mention = True, \n",
    "                        _remove_duplicate_char = True,\n",
    "                        _remove_single_char = True, \n",
    "                        _remove_new_line_char = True, \n",
    "                        _remove_number = True, \n",
    "                        _remove_html_tags = True, \n",
    "                        _remove_special_character = True, \n",
    "                        _remove_longest_than = True, \n",
    "                        _remove_whitespace = True, \n",
    "                        _remove_unicode_characters = True,\n",
    "                        _stemmer = False, \n",
    "                        _remove_non_english = True, \n",
    "                        _remove_stop_words = True, \n",
    "                        _lemmatizer = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['Normalized_Review'] = Train['Review'].apply(lambda x: text_normalization.normalization(x))\n",
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test['Normalized_Review'] = Test['Review'].apply(lambda x: text_normalization.normalization(x))\n",
    "Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Unique Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueWords_Train = set()\n",
    "for word in Train['Normalized_Review'].str.split():\n",
    "    UniqueWords_Train.update(word)\n",
    "len(UniqueWords_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueWords_Test = set()\n",
    "for word in Test['Normalized_Review'].str.split():\n",
    "    UniqueWords_Test.update(word)\n",
    "len(UniqueWords_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Train, target='Negative', width=1500, hieght=800, text='Normalized_Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Train, target='Positive', width=1500, hieght=800, text='Normalized_Review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Test, target='Negative', width=1500, hieght=800, text='Normalized_Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(data=Test, target='Positive', width=1500, hieght=800, text='Normalized_Review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MostFrequentWord_Train = Counter((Train['Normalized_Review']).str.split().explode()).most_common(15)\n",
    "MostFrequentWordDF_Train = pd.DataFrame(MostFrequentWord_Train, columns=('Word', 'Count'))\n",
    "MostFrequentWordDF_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_figure(data=MostFrequentWordDF_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(data=MostFrequentWordDF_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MostFrequentWord_Test = Counter((Test['Normalized_Review']).str.split().explode()).most_common(15)\n",
    "MostFrequentWordDF_Test = pd.DataFrame(MostFrequentWord_Test, columns=('Word', 'Count'))\n",
    "MostFrequentWordDF_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_figure(data=MostFrequentWordDF_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(data=MostFrequentWordDF_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"Number of Words\"] = Train[\"Normalized_Review\"].apply(lambda n:len(word_tokenize(n)))\n",
    "Train.drop(Train[Train[\"Number of Words\"] == 0].index, inplace = True)\n",
    "Train[\"Number of Words\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test[\"Number of Words\"] = Test[\"Normalized_Review\"].apply(lambda n:len(word_tokenize(n)))\n",
    "Test.drop(Train[Test[\"Number of Words\"] == 0].index, inplace = True)\n",
    "Test[\"Number of Words\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Of Charachters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"Number of Charachters\"] = Train[\"Normalized_Review\"].str.len()\n",
    "Train[\"Number of Charachters\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test[\"Number of Charachters\"] = Test[\"Normalized_Review\"].str.len()\n",
    "Test[\"Number of Charachters\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNaumberOfWords_Train = int(np.round((Train[\"Number of Words\"].mean())))\n",
    "AverageNaumberOfWords_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNaumberOfWords_Test = int(np.round((Test[\"Number of Words\"].mean())))\n",
    "AverageNaumberOfWords_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number Of Charachters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfCharachters_Train = int(np.round(Train[\"Number of Charachters\"].mean()))\n",
    "AverageNumberOfCharachters_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageNumberOfCharachters_Test = int(np.round(Test[\"Number of Charachters\"].mean()))\n",
    "AverageNumberOfCharachters_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNaumberOfWords_Train = Train[\"Number of Words\"].max()\n",
    "MaximumNaumberOfWords_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNaumberOfWords_Test = Test[\"Number of Words\"].max()\n",
    "MaximumNaumberOfWords_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Number Of Charachters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfCharachters_Train = Train['Number of Charachters'].max() \n",
    "MaximumNumberOfCharachters_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaximumNumberOfCharachters_Test = Test['Number of Charachters'].max() \n",
    "MaximumNumberOfCharachters_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MimimumNaumberOfWords_Train = Train[\"Number of Words\"].min()\n",
    "MimimumNaumberOfWords_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MimimumNaumberOfWords_Test = Test[\"Number of Words\"].min()\n",
    "MimimumNaumberOfWords_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Number Of Charachters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfCharachters_Train = Train['Number of Charachters'].min() \n",
    "MinimumNumberOfCharachters_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumNumberOfCharachters_Test = Test['Number of Charachters'].min() \n",
    "MinimumNumberOfCharachters_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset Into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Train['Normalized_Review'], Test['Normalized_Review'], Train['Sentiment'], Test['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Dependent Variables (Y) Into Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer_ = CountVectorizer()\n",
    "X_train_CV_ = CountVectorizer_.fit_transform(X_train)\n",
    "X_test_CV_ = CountVectorizer_.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Voc = CountVectorizer_.vocabulary_\n",
    "Voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = MultinomialNB(alpha= 1)\n",
    "Naive_Bayes = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Naive_Bayes, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=Naive_Bayes, X_test=X_test_CV_, y_test=y_test, name='Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= Naive_Bayes, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = LogisticRegression()\n",
    "Logistic_Regression = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Logistic_Regression, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(Logistic_Regression, X_test=X_test_CV_, y_test=y_test, name='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= Logistic_Regression, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = DecisionTreeClassifier(criterion='gini')\n",
    "Decision_Tree = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Decision_Tree, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=Decision_Tree, X_test=X_test_CV_, y_test=y_test, name='Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= Decision_Tree, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4-K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm =KNeighborsClassifier(metric='manhattan', n_neighbors=5)\n",
    "K_Nearest_Neighbors = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=K_Nearest_Neighbors, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=K_Nearest_Neighbors, X_test=X_test_CV_, y_test=y_test, name='K Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= K_Nearest_Neighbors, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = RandomForestClassifier(criterion = 'entropy', n_estimators=300)\n",
    "Random_Forest = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=Random_Forest, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=Random_Forest, X_test=X_test_CV_, y_test=y_test, name='Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= Random_Forest, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6-SGD Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = SGDClassifier(loss='hinge')\n",
    "SGD = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=SGD, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=SGD, X_test=X_test_CV_, y_test=y_test, name='SGD Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= SGD, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7-Multilayer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = MLPClassifier(hidden_layer_sizes=16)\n",
    "MLP = machine_learning_model(algorithm=Algorithm)\n",
    "fit_model(model=MLP, X_train=X_train_CV_, y_train=y_train)\n",
    "confusion_matrix_(model=MLP, X_test=X_test_CV_, y_test=y_test, name='Multilayer Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_values(model= MLP, X_test=X_test_CV_, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "vocab_size, max_length, encoded_X_train , encoded_X_test = deeplearning_preprcosesing_(X_train=X_train, X_test=X_test,  truncating='pre', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Vocab Size Is :',vocab_size)\n",
    "print('')\n",
    "print('The Max Length Is :', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"accuracy\",\n",
    "                    mode=\"max\",\n",
    "                    patience=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8-Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_neural_network = convolutional_neural_network_1d(vocab_size=vocab_size + 1, embedding_dim=embedding_dim, max_length=max_length, dropout=0.6, kernel=2, filters=32, strides=3, padding='same')\n",
    "model_compile(model=convolutional_neural_network)\n",
    "history = model_fit(model=convolutional_neural_network, X_train=encoded_X_train, y_train=y_train, epochs=10, X_test=encoded_X_test, y_test=y_test, batch_size=32, Callback=Callback, shuffle=True)\n",
    "plot_accuracy_loss(histoty=history)\n",
    "evaluate(model=convolutional_neural_network, x=encoded_X_train, y=y_train, train_test='Training')\n",
    "evaluate(model=convolutional_neural_network, x=encoded_X_test, y=y_test, train_test='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9-LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM =lstm_(vocab_size= vocab_size + 1, embedding_dim= embedding_dim, max_length= max_length, dropout=0.5, units=64)\n",
    "model_compile(model=LSTM)\n",
    "history = model_fit(model=LSTM, X_train=encoded_X_train, y_train=y_train, epochs=5, X_test=encoded_X_test, y_test=y_test, batch_size=64, Callback=Callback, shuffle=True)\n",
    "plot_accuracy_loss(histoty=history)\n",
    "evaluate(model=LSTM, x=encoded_X_train, y=y_train, train_test='Training')\n",
    "evaluate(model=LSTM, x=encoded_X_test,y= y_test, train_test='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_=gru_(vocab_size= vocab_size + 1, embedding_dim= embedding_dim, max_length= max_length, dropout=0.3, units=64)\n",
    "model_compile(model=GRU_)\n",
    "history = model_fit(model=GRU_, X_train=encoded_X_train, y_train=y_train, epochs=5, X_test=encoded_X_test, y_test=y_test, batch_size=64, Callback=Callback, shuffle=True)\n",
    "plot_accuracy_loss(histoty=history)\n",
    "evaluate(model=GRU_, x=encoded_X_train, y=y_train, train_test='Training')\n",
    "evaluate(model=GRU_, x=encoded_X_test,y= y_test, train_test='Testing')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In Future Work I Wiil Try To Decrease The Loss Values\n",
    "* Using Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
